# End-to-End Human Pose and Mesh Reconstruction with Transformers

# Abstract

- **```METRO(Mesh TRansfOrmer)```** 이라는 새로운 방법 제시(single image로 3D human pose&mesh vertices 재구성)
- **transformer encoder**를 이용해 vertex-vertex 와 vertex-joint **iteraction**를 jointly model함

**OUTPUT** : 3D joint coordinates와 mesh vertices 를 동시에 뽑아냄

- 차별점
  - 기존 모델: pose와 shape parameter를 regress함
  - 기존 모델(SMPL): parametric mesh models에 의존
  - ```METRO```: 파라미터에 의존하지 않음 -> 덕분에 hands와 같은 다른 object로도 확장이 용이

- 장점
  - transformer self-attention mechanism이 mesh topology 필요성을 줄이고 두 vertices 사이에서 freely attend 하게 함
    - 저렇게 함으로써, mesh vertices 와 joints 사이의 **non-local relationships**을 학습하는 것이 가능해짐
- proposed **masked vertex modeling**를 통해 **robust**하고 **partial occlusion**같은 challenging situation를 다루는데 효과적임


```parametric mesh model > masked vertex modeling```

- Human3.6M과 3DPW 데이터셋에서 human mesh reconstruction에 대한 SOTA 결과를 냄
- 3D human reconstruction에서 현재 SOTA인 FreiHAND 데이터셋을 능가하는 범용성을 보임

# Introduction

### CONTRIBUTION [4가지]
- NEW transformer-based method(METRO)
  - 3D human pose and mesh reconstruction from a single image
  - single image로부터 3D human pose and mesh를 reconstruction을 하는 새로운 transformer-based method 도입
- the Masked Vertex Modeling objective
  - better reconstruction을 위해 vertex-vertex 와 vertex-joint interaction을 모델링하기 위해 multi-layer transformer encoder을 포함한 Masked Vertex Modeling objective 디자인함 
- METRO : human mesh (Human3.6M과 challenging 3DPW 데이터셋에서 SOTA)
- METRO : hands (FreiHAND 리더보드에서 1위) - Generalization
  - 다른 타입의 3D mesh를 예측할 수 있음

---


- VR, 스포츠 모션 분석, 신경퇴행성 진단 분석 등에서 3D human pose/mesh reconstruction의 관심이 높아짐
- 그러나 complex articulated motion과 occlusion으로 인해 challenging 함


### 이 분야의 work는 **두가지 범주**로 나눌 수 있음

#### 1. ```SMPL```과 같은 **parametric model**를 이용
- **강점**: shape와 pose coefficients를 예측하도록 학습되는데 environment variations에 robust 함
- **단점**: pose와 shape space가 parametric model을 구축하는데 사용되는 limited exemplars에 의해 제한된다는 것
  - 이것을 극복하기 위한 두번째 방법이 고안

#### 2. **Graph convolution neural network(GCNN)나 1D heatmap**를 이용
graph convolutional neural network(to model neighborhood vertex-vertex interactions)  
1D heatmap(to regress vertex coordinates)

- **단점**: non-local vertex-vertex interaction을 모델하는데 효과적이지 않음


---

- 선행 연구에서 다른 body part(ex. hand-foot)에 소속된 non-local vertices 사이에 strong correlation이 있다고 보여짐
- [Computer Graphics & Robotics] inverse kinetics techniques(역운동학 기술) 는 hand tip과 같은 end effector의 position을 받은 articulated figure의 Internal joint position을 estimate 하도록 개발됨

---

### 필요성
- 우리는 short range와 long range를 포함하여 ```body joints와 mesh vertices 사이의 correlation을 학습```하는 것이 challenging한 pose와 occlusions를 핸들링하는데 필요하다 생각

### METRO 모델
- 본 논문에서는 **global vertex-vertex interactions**를 모델링하는 심플하지만 효과적인 프레임워크 제시 -> **주구성요소는 transformer**임


### Transformer(자연어 처리)
- 최근의 연구는 transformer의 **self-attention mechanism** 덕분에 다양한 task의 성능향상을 보여줌
- transformer은 특히 input과 output사이의 거리 상관없이 **dependencies(or interactions)를 모델링**하는데 효과적
- transformer는 relevant token을 soft-search할 수 있고, 중요한 features에 기반하여 예측함

---

### 본 논문
- (progressive dimension reduction을 사용하는) multi-layer transformer encoder 인 ```METRO```제안
  - input image로부터 **3D body joint**와 **mesh vertices**를 동시적으로 reconstruct함
- ```transformer encoder architecture```에 **```masked vertex modeling object````**를 추가하여 joints와 vertices사이의 interaction을 강화함
- figure1과 같이 ```METRO```는 joints와 mesh vertices사이의 short-range와 long-range interaction를 발견하도록 학습하여 큰 pose변화와 occlusion을 가진 3D human pose를 reconstruct하는데 도움이 되도록 함

### 실험 결과
- ```METRO```가 vertex-vertex와 vertex-joint interaction을 하는데 효과적이고, human mesh reconstruction에 있어서 large margin을 두고 이전 연구를 뛰어넘는 것을 보여줌
- METRO는 single image로부터 3D human pose와 mesh reconstruction을 jointly learn하는데에 **transformer encoder**를 사용한 첫번째 시도
- 또한, METRO는 input image로부터 3D hand를 reconstruct하는 등 다른 3D mesh를 에측하는데 쉽게 적용되는 general framework



![image](https://user-images.githubusercontent.com/72767245/126170999-70c2706f-ff1c-42fe-a0ef-c570411c1cec.png)

- ```METRO```는 human mesh reconstruction을 위해 body joints와 mesh vertices사이의 non-local interactions를 학습
- (a) input image, ```METRO```는 non-local interactions을 고려하여 human mesh를 예측한다
- (b) occluded wrist joint와 mesh vertices의 attention (brighter color일 수록 강한 attention 의미)
- (c) reconstruct mesh 

# Related Works
## Human Mesh Reconstruction(HMR)
3D human body shape를 reconstruct하는 Task  
초기 연구는 다양한 센서를 이용해서 reconstruction을 수행함 -> 점차 효과적이고 간편한 monocular camera 이용하려함  
하지만, single image로부터의 HMR은 **pose variation, occlusions, limited 3D training data**로 어려움

1. 이전 연구들(SMPL, STAR, MANO)등의 사전학습된 ```parametric human models```를 제안함
- HMR에 대한 parametric model의 pose와 shape coefficient를 estimate함
  - 그러나 input image로부터 바로 pose와 shape coefficients를 regress하는 것은 어렵기 때문에 human skeletons 나 segmentation map과 같은 human body를 다루기도 함

2. parametric human model을 채택하는 것 대신, input image를 통해 human body를 directly하게 regress하는 방법
(방법) **3D mesh, volumetric space, occupancy field**등을 이용해서 represent  
- **GraphCMR**:  3D mesh vertices를 graph convolutional neural networks(GCNN)를 이용해 regress하는 것이 목표
- **pose2Mesh**(최근): GCNN을 이용한 cascaded model임
  - Pose2Mesh는 주어진 human pose representation을 기반으로 human mesh을 재구성함

### GCNN based method
**GCNN** based method는 pre-specified mesh topology를 이용하여 neighborhood vertex-vertex interactions를 모델링하도록 디자인했는데 longer range interactions를 모델링하는데 덜 효과적임

> 반면에 METRO models는 어떠한 mesh topology에 국한되지 않고 joints와 mesh vertices사이의 global interactions를 모델링 가능

## Attentions and Transformers
- 최근의 연구들은 **attention mechanism**이 다양한 language tasks의 성능향상을 보여줌
- ```key insight```는 output을 예측하는데에 있어서 더 중요한 **relevant inputs를 soft-search해서 attention**한다는 것
- Vaswani et al. 은 attention mechanisms 만을 기반으로 한 transformer architecture을 제안함
- Transformer은 (효율적인 train과 inference을 위하여) multi-head self-attention을 이용하여 highly parallelized(고도로 병렬화 됨)함 -> NLP분야에서 높은 성능을 보임
- BERT와 GPT에서 살펴본 것 처럼 규모에 맞는 언어 모델링에서 탁월한 성능을 이끌어 냄
- NLP 분야의 성공으로 인해 **vision분야**에서도 image generation에 있어서 pixel distributions를 학습하거나 분류, detection등의 task에 transformer를 이용해보려는 시도가 있음
  - 하지만 3D human reconstruction에서는 이러한 방향으로의 시도가 없었음


> we present a multi-layer transformer architecture with progressive dimensionality reduction to regress the 3D coordinates of the joints and vertices.

- 해당 논문에서는 progressive dimensionality reduction을 이용해서 joints와 vertices를 regress하는 multi-layer transformer architecture를 제시함


# Method

![image](https://user-images.githubusercontent.com/72767245/126182117-1dad009d-69fb-4aa6-89d2-649ea13f48ad.png)

- ```INPUT```: 224x224 image
- ```OUTPUT```: body joints J and mesh vertices V
- 두가지 ```MODULES```:
  - 1. Convolutional Neural Networks: input image로부터 feature vector를 뽑아냄
  - 2. Multi-Layer Transformer Encoder: feature vector를 input으로 받아서 body joints와 mesh vertex의 3D coordinates로 받음

- 1. CNN사용: input image을 통해 to extract an image feature vector
- 2. Multi-Layer Transformer Encoder: takes as input the feature vector and outputs the 3D coordinates of the body joint and mesh vertex in parallel.



## 1. Convolutional Neural Networks
- feature extraction을 위하여 사용
- ImageNet 분류 문제로 사전 학습되어 있음
- 마지막 Hidden layer에서 feature vectore를 추출(2048d)
- 추출된 feature vector X를 Transformer에 input으로 사용해 regress
- Transformer은 HRNETs와 같이 large-scale pre-trained CNN으로 이득을 얻음
- 본 실험에서 우리는 input feature를 분석해, high resolution image features가 유용하다는 것을 발견

## 2. Multi-Layer Transformer Encoder with Progressive Dimensionality Reduction
